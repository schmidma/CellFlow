{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import torch\n",
    "from pathlib import Path \n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "ROOT_DIR = Path(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tifffile.imread(ROOT_DIR / \"train/a_GT/man_seg0474.tif\") != 0\n",
    "\n",
    "mask_gradients = tifffile.imread(ROOT_DIR / \"train/a_flow/seg0474_gradients.tif\")\n",
    "mask_gradients = torch.tensor(mask_gradients[[1, 0], :, :]).unsqueeze(0)\n",
    "\n",
    "batch_size = mask_gradients.shape[0]\n",
    "image_height = mask_gradients.shape[2]\n",
    "image_width = mask_gradients.shape[3]\n",
    "\n",
    "# positions in (batch_size, image_height, image_width, 2)\n",
    "positions = (\n",
    "    torch.cartesian_prod(\n",
    "        torch.arange(image_height),\n",
    "        torch.arange(image_width),\n",
    "    )\n",
    "    .reshape(image_height, image_width, 2)\n",
    "    .unsqueeze(0)\n",
    "    .repeat(batch_size, 1, 1, 1)\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions /= (\n",
    "    torch.tensor([image_height, image_width]).double().unsqueeze(0).unsqueeze(0)\n",
    ")\n",
    "positions = positions * 2 - 1\n",
    "\n",
    "mask_gradients *= 2.0 / torch.tensor([image_height, image_width]).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "# positions = positions[:, :, :, [1, 0]]\n",
    "for _ in range(100):\n",
    "    gradients = torch.nn.functional.grid_sample(\n",
    "        mask_gradients, positions, align_corners=False\n",
    "    )\n",
    "    for k in range(2):\n",
    "        positions[:,:,:,k] = torch.clamp(positions[:,:,:,k] + gradients[:,k,:,:], -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = (positions + 1) / 2\n",
    "positions *= (\n",
    "    torch.tensor([image_height, image_width]).double().unsqueeze(0).unsqueeze(0)\n",
    ")\n",
    "px.scatter(\n",
    "    x=positions[0, :, :, 1][mask], y=positions[0, :, :, 0][mask]\n",
    ").update_yaxes(scaleanchor=\"x\", scaleratio=1,).update_layout(width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
